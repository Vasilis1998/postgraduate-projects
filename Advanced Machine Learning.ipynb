{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR3BUlygJOlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5902ea3a-e274-48da-dfb5-e88e263ad0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "!pip install -U tensorflow-addons\n",
        "!pip install pydicom\n",
        "!pip install transformers\n",
        "!pip install folium==0.2.1\n",
        "!pip install -q transformers datasetsimport pandas as pd\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "import cv2\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "import random\n",
        "import shutil\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import pydicom as dicom\n",
        "import zipfile\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras import backend as K\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from transformers import ConvNextFeatureExtractor\n",
        "from torchvision.transforms import Compose, Normalize, RandomHorizontalFlip, RandomResizedCrop, Resize, ToTensor\n",
        "from transformers import AutoModelForImageClassification\n",
        "from datasets import load_dataset\n",
        "import statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the datasets\n",
        "train_path = '/content/drive/MyDrive/AML_Kaggle_Competition/train_images'\n",
        "test_path = '/content/drive/MyDrive/AML_Kaggle_Competition/test_images'\n",
        "labels_path = '/content/drive/MyDrive/AML_Kaggle_Competition/labels_train.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3mWznxloEj4",
        "outputId": "07fd761e-2622-4b07-84ed-658a66594989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st MODEL: DENSENET121**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "g6_3T46RuX4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file containing the image labels\n",
        "labels_df = pd.read_csv(labels_path)\n"
      ],
      "metadata": {
        "id": "npygpx6soICW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['class_id'])\n",
        "\n",
        "train_df['class_id'] = train_df['class_id'].astype(str)\n"
      ],
      "metadata": {
        "id": "GKkf1nJ4oLWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ImageDataGenerator for data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "NmBicdhfoOrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert class_id values to strings in the validation data DataFrame\n",
        "val_df['class_id'] = val_df['class_id'].astype(str)\n"
      ],
      "metadata": {
        "id": "jLNaOS6goXZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target image size and hyperparameters\n",
        "batch_size = 200\n",
        "target_size = (224, 224)\n",
        "epochs = 100\n",
        "lr = 0.0001"
      ],
      "metadata": {
        "id": "ikK25OBrxNE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training and validation data generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory=train_path,\n",
        "    x_col='file_name',\n",
        "    y_col='class_id',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    directory=train_path,\n",
        "    x_col='file_name',\n",
        "    y_col='class_id',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeSxx9EkohJo",
        "outputId": "f41a7726-fb99-4d47-f2ab-c3f864ba32b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4204 validated image filenames belonging to 3 classes.\n",
            "Found 468 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of file paths for the test images\n",
        "test_files = os.listdir(test_path)\n",
        "test_files = [os.path.join(test_path, file) for file in test_files]\n",
        "\n",
        "# Create a dataframe that lists the file paths\n",
        "test_df = pd.DataFrame({'filename': test_files})\n",
        "\n",
        "# Define the test data generator using flow_from_dataframe\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "sFx61fB6olX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a7b1825-dc33-456e-ca3f-ac6e4192bc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1168 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load pre-trained DenseNet121 model\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "\n",
        "# add custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "wIIVlHTwonT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "utTgR9RMRIDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = RMSprop(learning_rate = lr)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "kcMq3LbzE2cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the checkpoint filepath and settings\n",
        "checkpoint_filepath = '/content/drive/MyDrive/AML_Kaggle_Competition/AML_Coursework_DenseNet121_rmsprop.h5'\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch',  # Save after each epoch\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "X6FcNeKFv9jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/AML_Kaggle_Competition/AML_Coursework_DenseNet121_rmsprop.h5')"
      ],
      "metadata": {
        "id": "G8ljaat7yw8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "d--4O8u9otmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_generator)\n"
      ],
      "metadata": {
        "id": "MkCjLX-koyy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the filenames of the test images and remove the path and directory\n",
        "filenames = [filename.split('/')[-1] for filename in test_generator.filenames]\n",
        "\n",
        "# Create a DataFrame containing the filenames and predicted classes\n",
        "df1 = pd.DataFrame({'file_name': filenames, 'class_id': predicted_classes})"
      ],
      "metadata": {
        "id": "bnnTNlNwo6Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2nd MODEL: XCEPTION**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I9mZKlQK0vjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file containing the image labels\n",
        "labels_df = pd.read_csv(labels_path)\n"
      ],
      "metadata": {
        "id": "SWhTznL44RCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target image size and hyperparameters\n",
        "batch_size = 32\n",
        "target_size = (224, 224)\n",
        "epochs = 100\n",
        "lr = 0.0001\n",
        "num_folds = 4"
      ],
      "metadata": {
        "id": "Xuvss_l85JUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the KFold object\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Define the checkpoint filepath and settings\n",
        "checkpoint_filepath = '/content/drive/MyDrive/AML_Kaggle_Competition/AML_Coursework_Xception.h5'\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch',  # Save after each epoch\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "puzlqHMV5Lik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation sets\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['class_id'])\n",
        "\n",
        "train_df['class_id'] = train_df['class_id'].astype(str)\n"
      ],
      "metadata": {
        "id": "VHJEvMW9rUdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to normalize the pixel values\n",
        "def normalize(x):\n",
        "    x = x / 255.0\n",
        "    mean = np.mean(x)\n",
        "    std = np.std(x)\n",
        "    return (x - mean) / std\n",
        "\n"
      ],
      "metadata": {
        "id": "NhNIMqDWrWP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the ImageDataGenerators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
      ],
      "metadata": {
        "id": "3dch2FtW5Ph3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training and validation data generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory=train_path,\n",
        "    x_col='file_name',\n",
        "    y_col='class_id',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    directory=train_path,\n",
        "    x_col='file_name',\n",
        "    y_col='class_id',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n"
      ],
      "metadata": {
        "id": "Z5Xr96oR6Ede"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of file paths for the test images\n",
        "test_files = os.listdir(test_path)\n",
        "test_files = [os.path.join(test_path, file) for file in test_files]\n",
        "\n",
        "# Create a dataframe that lists the file paths\n",
        "test_df = pd.DataFrame({'filename': test_files})\n",
        "\n",
        "# Define the test data generator using flow_from_dataframe\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "THeN5v4L6IiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained Xception model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "# add custom layers on top\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "K8XRM8yu9ibC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze the weights of the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "TniKMGez9l_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate = lr)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "y_86pkRA9oXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rate reduction settings\n",
        "learn_control = ReduceLROnPlateau(monitor='accuracy', patience=3, verbose=1, factor=.5, min_lr=0.000005)"
      ],
      "metadata": {
        "id": "dncnjB469rVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[checkpoint_callback]) # learn_control\n"
      ],
      "metadata": {
        "id": "XPnYBdUL9zvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_generator)\n"
      ],
      "metadata": {
        "id": "Yf3N-HmX93TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the filenames of the test images\n",
        "filenames = test_generator.filenames\n",
        "\n",
        "# Create a DataFrame containing the filenames and predicted classes\n",
        "df2 = pd.DataFrame({'file_name': filenames, 'class_id': predicted_classes})\n"
      ],
      "metadata": {
        "id": "81EHv5iO95a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3d MODEL: VIT**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xaTwb-m3CWtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# preparation the data\n",
        "num_classes = 3\n",
        "input_shape = (256, 256, 3)\n",
        "#Loading test images & test labels from the respective datasets\n",
        "labels = pd.read_csv('/content/drive/MyDrive/AML_Kaggle_Competition/labels_train.csv')\n",
        "norm_labels = []\n",
        "norm_images = []\n",
        "norm_path=os.listdir('/content/drive/MyDrive/AML_Kaggle_Competition/train_images')\n",
        "# retrieving the lables to preserve the order\n",
        "for image in tqdm(norm_path):\n",
        "  lbl = labels.loc[labels.file_name == image, 'class_id'].iloc[-1]\n",
        "  norm_labels.append(lbl)\n",
        "  image = cv2.imread('/content/drive/MyDrive/AML_Kaggle_Competition/train_images/train' + image)\n",
        "  image = cv2.resize(image, dsize=(256,256))\n",
        "  norm_images.append(image)\n",
        "\n",
        "# converting the images into numpy arays\n",
        "norm_images = np.array(norm_images)\n",
        "norm_labels = np.array(norm_labels)"
      ],
      "metadata": {
        "id": "5YNEuXs0Cc9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split (80%)\n",
        "X_train = norm_images[:3737,:,:]\n",
        "X_test=norm_images[3737:,:,:]\n",
        "y_train = norm_labels[:3737]\n",
        "y_test=norm_labels[3737:]"
      ],
      "metadata": {
        "id": "4w35X20mCkDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the x_train & x_test shapes\n",
        "print(f\"x_train shape: {X_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {X_test.shape} - y_test shape: {y_test.shape}\")\n",
        ""
      ],
      "metadata": {
        "id": "zrjns-duCmkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding one more axis to the test sets\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "# print with the new dimensions\n",
        "print(f\"x_train shape: {X_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {X_test.shape} - y_test shape: {y_test.shape}\")\n",
        ""
      ],
      "metadata": {
        "id": "ctpmXTL-Copa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration of the hyperparameters\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "num_epochs = 100\n",
        "batch_size = 256\n",
        "image_size = 144  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]\n",
        "# Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
      ],
      "metadata": {
        "id": "O1Yph5BDCrEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(X_train)"
      ],
      "metadata": {
        "id": "vdg5Hz8aCtfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to implement multilayer perceptron (MLP)\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "c-3IzL5xCvlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class to implement patch creation as a layer\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "li94L_7xCxfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation of the patch encoding layer\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "LT3sfU8SCzzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# built the ViT model\n",
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "id": "CYYX6YPHC9gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile, train, and evaluate the mode\n",
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\")])\n",
        "\n",
        "    checkpoint_filepath = \"/content/drive/MyDrive/AML_Kaggle_Competition/vit.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        epochs= num_epochs,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[checkpoint_callback ]\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ],
      "metadata": {
        "id": "P6l3soXDDHza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot accuracy scores and Loss value\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Accuracy scores')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['acc', 'val_acc'])\n",
        "plt.show()\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Loss value')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rBfaaJacDde4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading target images from the respective dataset\n",
        "target_images = []\n",
        "file_name=[]\n",
        "test_path=os.listdir('/content/drive/MyDrive/AML_Kaggle_Competition/test_images')\n",
        "for test_image in tqdm(test_path):\n",
        "  file_name.append(test_image)\n",
        "  test_image = cv2.imread('/content/drive/MyDrive/AML_Kaggle_Competition/test_images/' + test_image)\n",
        "  test_image = cv2.resize(test_image, dsize=(256,256))\n",
        "  target_images.append(test_image)\n",
        "\n",
        "target_images = np.array(target_images)\n",
        "Target = target_images\n",
        ""
      ],
      "metadata": {
        "id": "8eF_HaOJDev1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction of test images\n",
        "predictions = vit_classifier.predict(Target)\n",
        "predictions = predictions.argmax(axis=1)"
      ],
      "metadata": {
        "id": "GtqFZsLHDj5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of the 1st prediction dataframe\n",
        "df3 = pd.DataFrame()\n",
        "df3['file_name'] = file_name\n",
        "df3['class_id'] = predictions"
      ],
      "metadata": {
        "id": "Z9tUaWR0DlJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAJORITY VOTE OF THE THREE MODEL RESULTS**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3T68Oo99xZsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the three DataFrames on the 'file_name' column\n",
        "merged_df = df1.merge(df2, on='file_name').merge(df3, on='file_name')\n",
        "\n",
        "# Compute the mode (most frequent value) of the 'class_id' columns for each row\n",
        "mode_series = merged_df[['class_id_x', 'class_id_y', 'class_id']].mode(axis=1)\n",
        "\n",
        "# Extract the mode values and convert them to integers\n",
        "mode_values = mode_series.iloc[:, 0].astype(int)\n",
        "\n",
        "# Create a new DataFrame with the file names and mode values\n",
        "results_df = pd.DataFrame({'file_name': merged_df['file_name'], 'class_id': mode_values})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('/content/drive/MyDrive/AML_results/resultstobesent_majority.csv', index=False)"
      ],
      "metadata": {
        "id": "XGg1KZuaxVEY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}